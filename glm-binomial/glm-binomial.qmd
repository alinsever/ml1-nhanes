---
title: "Binomial GLM"
format: 
  html:
    toc: true
    toc-depth: 4
    code-fold: true
    code-fold-show: false
    code-summary: "Show/Hide Code"
  
---

```{r}
#| label: "libraries"
#| warning: false
#| message: false

library(tidyverse)
library(patchwork)
library(NHANES)
library(car)
library(pROC)
library(mgcv)
library(here)

```

```{r}
#| label: "nhanes dataset"
#| include: false

data(NHANES)
# str(NHANES)

# Subset with ~20 variables (all types included)
nhanes_sub <- NHANES %>%
  select(
    # demography
    SurveyYr, Gender, Age, AgeDecade, Race1, Education, MaritalStatus,
    HHIncome, HHIncomeMid, Poverty, HomeRooms, HomeOwn,
    
    # health (continuous + categorical)
    Height, Weight, BMI, HealthGen,
    Pulse, BPSysAve, BPDiaAve,
    
    # behaviour & life style
    PhysActive, PhysActiveDays, SleepHrsNight, SleepTrouble,
    Alcohol12PlusYr, AlcoholDay, AlcoholYear,
    SmokeNow, Smoke100, SmokeAge,
    
    # mental health
    DaysPhysHlthBad, DaysMentHlthBad,
    LittleInterest, Depressed
  )

str(nhanes_sub)

```

## Generalized Linear Model (family: Binomial)

### Make outcome variable Depressed (three levels) binary

```{r}
#| label: "Depressed binomial"
#| warning: false
#| message: false

summary(nhanes_sub$Depressed)

nhanes_sub <- nhanes_sub %>%
  mutate(
    Depressed_bin = case_when(
      Depressed == "None" ~ "no",
      Depressed %in% c("Several", "Most") ~ "yes",
      TRUE ~ NA_character_
    ),
    Depressed_bin = factor(Depressed_bin, levels = c("no", "yes"))
  )

# Check the recode
table(nhanes_sub$Depressed, nhanes_sub$Depressed_bin, useNA = "ifany")

```

### Visual inspection of Variable Depressed_bin

```{r}
#| label: "Depressed_bin Visuals"
#| warning: false
#| message: false
#| fig-height: 3
#| fig-width: 6

p_sleep_hours <- ggplot(
  filter(nhanes_sub, !is.na(Depressed_bin)),
  aes(x = Depressed_bin, y = SleepHrsNight)
) +
  geom_boxplot() +
  labs(title = "Sleep Hours vs Depression",
       x = "Depressive Symptoms", y = "Sleep Hours")

p_sleep_trouble <- ggplot(
  filter(nhanes_sub, !is.na(Depressed_bin)),
  aes(x = SleepTrouble, fill = Depressed_bin)
) +
  geom_bar(position = "fill") +
  labs(title = "Sleep Trouble vs Depression",
       x = "Sleep Trouble", y = "Proportion") +
  scale_y_continuous(labels = scales::percent_format())

p_sleep_hours + p_sleep_trouble


p_age <- ggplot(
  filter(nhanes_sub, !is.na(Depressed_bin)),
  aes(x = Depressed_bin, y = Age)
) +
  geom_boxplot() +
  labs(title = "Age vs Depression",
       x = "Depressive Symptoms", y = "Age")

p_poverty <- ggplot(
  filter(nhanes_sub, !is.na(Depressed_bin)),
  aes(x = Depressed_bin, y = Poverty)
) +
  geom_boxplot() +
  labs(title = "Poverty Index vs Depression",
       x = "Depressive Symptoms", y = "Poverty Index")

p_age + p_poverty


p_health <- ggplot(
  filter(nhanes_sub, !is.na(Depressed_bin)),
  aes(x = HealthGen, fill = Depressed_bin)
) +
  geom_bar(position = "fill") +
  labs(title = "General Health vs Depression",
       x = "General Health", y = "Proportion") +
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  scale_y_continuous(labels = scales::percent_format())

p_phys <- ggplot(
  filter(nhanes_sub, !is.na(Depressed_bin)),
  aes(x = PhysActive, fill = Depressed_bin)
) +
  geom_bar(position = "fill") +
  labs(title = "Physical Activity vs Depression",
       x = "Physical Activity", y = "Proportion")

p_health + p_phys

# # Gender vs Depressed
# ggplot(filter(nhanes_sub, !is.na(Depressed_bin)), aes(x = Gender, fill = Depressed_bin)) +
#   geom_bar(position = "fill")

# # MaritalStatus vs Depressed
# ggplot(filter(nhanes_sub, !is.na(Depressed_bin)), aes(x = MaritalStatus, fill = Depressed_bin)) +
#   geom_bar(position = "fill") +
#   theme(axis.text.x = element_text(angle=45, hjust=1))

# # PhysActive nach MaritalStatus
# ggplot(filter(nhanes_sub, !is.na(Depressed_bin)), 
#        aes(x = PhysActive, fill = Depressed_bin)) +
#   geom_bar(position = "fill") +
#   facet_wrap(~ MaritalStatus)

# # BMI vs Depressed
# ggplot(filter(nhanes_sub, !is.na(Depressed_bin)), aes(x = Depressed_bin, y = BMI)) +
#   geom_boxplot()

# library(ggmosaic)
# ggplot(filter(nhanes_sub, !is.na(Depressed_bin))) +
#  geom_mosaic(aes(x = product(Gender, MaritalStatus), fill = Depressed_bin)) +
#  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# # SleepTrouble nach Gender
# ggplot(filter(nhanes_sub, !is.na(Depressed_bin)), 
#        aes(x = SleepTrouble, fill = Depressed_bin)) +
#   geom_bar(position = "fill") +
#   facet_wrap(~ Gender)

```

### Selection of variables

Previous research has shown that depression is often associated with demographic, socioeconomic, social, health, and lifestyle factors. Based on these findings and after visual inspection of the graphs above, the following 9 variables are included in the first model:

-   **Demographic**: Age, Gender\
-   **Socioeconomic**: Poverty\
-   **Social**: MaritalStatus\
-   **Health-related**: BMI, HealthGen\
-   **Sleep / Activity**: SleepHrsNight, SleepTrouble, PhysActive

These choices are supported by findings in NHANES-based studies, where factors such as poverty, marital status, physical activity, sleep problems, BMI, and general health perception were among the strongest predictors of depression (see e.g. Zhang et al., *BMC Medical Informatics and Decision Making*, 2025).


### Handling of missings

```{r}
#| label: "Missings"
#| warning: false
#| message: false

Depressed_data <- nhanes_sub %>%
  filter(!is.na(Depressed_bin))

vars_model <- c("Depressed_bin", "Age", "Gender", "Poverty", "MaritalStatus", "BMI", "HealthGen", "SleepHrsNight", "SleepTrouble", "PhysActive")

Depressed_data %>%
  select(all_of(vars_model)) %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(),
                      names_to = "Variable", values_to = "Missing_Count")

```

It is feasible to **replace missings** in `Poverty`, `BMI` and `SleepHrsNight` by the **median**. For `MaritalStatus` I don't see a convincing approach to replace missings.

```{r}
#| label: "Impute_Missings"
#| warning: false
#| message: false

Depressed_data_imp <- Depressed_data %>%
  mutate(
    Poverty = ifelse(is.na(Poverty), median(Poverty, na.rm = TRUE), Poverty),
    BMI = ifelse(is.na(BMI), median(BMI, na.rm = TRUE), BMI),
    SleepHrsNight = ifelse(is.na(SleepHrsNight), median(SleepHrsNight, na.rm = TRUE), SleepHrsNight),)

# Depressed_data_imp %>%
#   select(all_of(vars_model)) %>%
#   summarise(across(everything(), ~ sum(is.na(.)))) %>%
#   pivot_longer(cols = everything(),
#                       names_to = "Variable", values_to = "Missing_Count")

saveRDS(Depressed_data_imp, "depressed_imp.rds")

```

I will continue the modelling with the imputed dataset where only `MaritalStatus` is missing for 236 cases.

### Model 1: Full model

```{r}
#| label: "GLM_Binomial_1"
#| warning: false
#| message: false

glm_depressed_1 <- glm(Depressed_bin ~ Age + Gender + Poverty + MaritalStatus + BMI +
                   HealthGen + SleepHrsNight + SleepTrouble + PhysActive,
                   data = Depressed_data_imp,
                   family = binomial)
summary(glm_depressed_1)

```

There is **strong evidence against the null hypothesis** that `Gender`, `Poverty`, `MaritalStatus`, `HealthGen`, `SleepHrsNight`, `SleepTrouble` and `PhysActivitie` have no effect. Whereas `Age` and `BMI` show **no significant effect** on Depressed_bin.

#### Checking for Collinearity

I am concerned about potential collinearity between the predictors, as this could hinder a proper interpretation of their individual effects. Therefore, I checked the model for signs of collinearity.

```{r}
#| label: "GLM_Binomial_1_Collinear"
#| warning: false
#| message: false

vif(glm_depressed_1)   # auf dein Modell anwenden

```

All VIF values are \<2, meaning the model does not suffer from collinearity.

### Model 2: Removing non-significant predictors

```{r}
#| label: "GLM_Binomial_2"
#| warning: false
#| message: false

glm_depressed_2 <- glm(Depressed_bin ~ Gender + Poverty + MaritalStatus + HealthGen + SleepHrsNight + SleepTrouble + PhysActive,
                       data = Depressed_data_imp,
                       family = binomial)
summary(glm_depressed_2)

```

Do all variables **contribute significantly** to the quality of the model?

```{r}
#| label: "Glm_depressed_2_drop1"
#| warning: false
#| message: false

drop1(glm_depressed_2, test = "Chisq")

```

As expected, all seven predictors substantially contribute to the model fit.

### Model 3: Removing conceptually collinear predictor (HealthGen)

I exclude HealthGen in Model 3 because it is conceptually very close to Depressed_bin: self-rated general health overlaps strongly with depressive symptoms. Since the goal here is to understand underlying relationships rather than to maximize predictive accuracy, HealthGen is removed from the final model.

```{r}
#| label: "GLM_Binomial_3"
#| warning: false
#| message: false

glm_depressed_3 <- glm(Depressed_bin ~ Gender + Poverty + MaritalStatus + SleepHrsNight + SleepTrouble + PhysActive,
                       data = Depressed_data_imp,
                       family = binomial)
summary(glm_depressed_3)

```

To evaluate the discriminatory power of this logistic regression model, a **ROC (Receiver Operating Characteristic)** analysis is performed using the pROC package.

```{r}
#| label: "GLM_Binomial_3_ROC"
#| warning: false
#| message: false
#| fig-height: 3
#| fig-width: 6

roc(glm_depressed_3$y, fitted(glm_depressed_3))

# ROC-Kurve plotten
roc_obj <- roc(glm_depressed_3$y, fitted(glm_depressed_3))
plot(roc_obj)

```

#### ANOVA: comparing GLM and GAM models

As a **preliminary check**, an analysis of deviance (ANOVA) is being conducted to test whether the GAM provides a statistically significant improvement over the simpler GLM.

```{r}
#| label: "ANOVA_model comparison"
#| warning: false
#| message: false

anova(glm_depressed_2, glm_depressed_3, test = "Chisq")

```

The analysis of deviance shows a highly significant increase in deviance when HealthGen is removed from the model (ΔDeviance = 146.46, p < 0.001), indicating that HealthGen provides substantial explanatory power. However, its strong conceptual overlap with depressive symptoms suggests caution when interpreting it as an independent predictor.

#### Akaike Information Criterion (AIC)

The AIC is a commonly used measure of model fit that balances model accuracy and complexity. It is chosen because it allows a direct **comparison between models with different numbers of parameters**, penalizing excessive complexity while rewarding better data fit.

```{r}
#| label: "AIC_GLM_model comparison"
#| warning: false
#| message: false

AIC(glm_depressed_3, glm_depressed_2)

```

The AIC comparison shows that the model including HealthGen (AIC = 5978.8) **outperforms the simpler model** without it (AIC = 6117.2). Because lower AIC values indicate a better balance of fit and complexity, this confirms that HealthGen provides substantial additional explanatory value.

### Confusion matrix

We next assess the predictive performance of the models using confusion matrices.

```{r}
#| label: "Evaluate models function"
#| echo: false
#| warning: false
#| message: false

eval_model <- function(model, threshold = 0.5) {
  pred_prob <- fitted(model)
  pred_class <- ifelse(pred_prob > threshold, "yes", "no")
  pred_class <- factor(pred_class, levels = c("no", "yes"))

  actual <- factor(ifelse(model$y == 1, "yes", "no"), levels = c("no", "yes"))

  cm <- table(Predicted = pred_class, Actual = actual)

  list(
    confusion_matrix = cm,
    accuracy = sum(diag(cm)) / sum(cm),
    sensitivity = cm[2,2] / sum(cm[,2]),
    specificity = cm[1,1] / sum(cm[,1]),
    precision = cm[2,2] / sum(cm[2,])
  )
}
```

Then we use the function to calculate these measures for the two models.

```{r}
#| label: "Evaluate models"
#| echo: false
#| warning: false
#| message: false

show_eval <- function(model, name) {
  cat("###", name, "\n")
  out <- eval_model(model)
  print(out$confusion_matrix)
  cat(
    sprintf("\nAccuracy: %.3f\nSensitivity: %.3f\nSpecificity: %.3f\nPrecision: %.3f\n",
            out$accuracy, out$sensitivity, out$specificity, out$precision)
  )
}

show_eval(glm_depressed_2, "GLM Model 2 (without Age and BMI)")
cat("\n")
show_eval(glm_depressed_3, "GLM Model 3 (without Age, BMI, HealthGen)")

```

#### Results of Confusion Matrices

Comparing the two GLM models shows that removing HealthGen (Model 3) leads to a clear drop in predictive performance. Model 2 achieves slightly higher accuracy (0.792 vs. 0.786), notably better sensitivity (0.151 vs. 0.094), and higher precision (0.553 vs. 0.502).
This indicates that HealthGen substantially improves the model’s ability to correctly identify depressed individuals, even though it may not be conceptually independent from the outcome.

#### Optimal classification threshold

Because the default threshold of 0.5 yielded very low sensitivity, adjusting the classification threshold can be reasonable. Lowering the threshold typically increases the model’s ability to identify depressed individuals, which may be more important depending on the research goal. Here the optimal threshold is determined based on the ROC curve for **model 3**.

```{r}
#| label: "Optimal_Threshold_GLM"
#| warning: false
#| message: false

coords(roc_obj, "best", ret = c("threshold", "sensitivity", "specificity"))
```

Based on the ROC analysis, the optimal classification threshold is approximately 0.22, which yields a substantially higher sensitivity (0.61) at a reasonable specificity level (0.69).
This indicates that lowering the threshold from the default 0.5 dramatically improves the model’s ability to detect depressed individuals, which may be more appropriate given the imbalance in the outcome and the higher cost of false negatives.

### Note on Overdispersion

Since the outcome variable `Depressed_bin` is **binary** (individual observations coded as 0/1), there is **no concern about overdispersion** in this analysis. Overdispersion is only relevant for **aggregated binomial data** (e.g., "15 successes out of 20 trials"), where the observed variance can exceed the variance assumed by the binomial model.

In this case, each observation follows a **Bernoulli distribution** (a special case of the binomial distribution with n=1), where the variance is fixed at p(1-p) and cannot be overdispersed.

### Final remark on model selection

Model 2, which includes `HealthGen`, provides the best statistical fit and is preferable for prediction. Model 3, which excludes `HealthGen`, yields a less optimal fit but offers clearer interpretability of the other predictors. Therefore, **Model 2** is suited for predictive purposes, whereas **Model 3** is more appropriate for understanding how socioeconomic and lifestyle factors relate to depressive symptoms.